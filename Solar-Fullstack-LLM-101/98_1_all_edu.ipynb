{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/Solar-Fullstack-LLM-101/98_1_all_edu.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upstage Solar Full Stack LLM 101\n",
    "## Code to Understand!\n",
    "![Overview](./figures/overview.png)\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "* <b> Session 1. Hello Solar </b> : Obtain an Upstage API Key and use the upstage chat model. <br>\n",
    "    - 1-1 Interacting with the Solar-1-mini-chat Model\n",
    "    - 1-2 Using Few-Shot Examples in Chat Completions\n",
    "\n",
    "\n",
    "- <b> Session 2. Building LLM Applications with LangChain</b> :  Learn how to easily implement LLM chains using LangChain and understand the features of LLMs.<br>\n",
    "    - 2-1 Prompt Engineering\n",
    "    - 2-2 Hallucinations\n",
    "    - 2-3 Groundedness Check with LangChain and Upstage\n",
    "\n",
    "\n",
    "- <b> Session 3. What is RAG? </b>:  Understand the concept of RAG, load documents, and implement a RAG system.<br>\n",
    "    - 3-1 Layout Analysis\n",
    "    - 3-2 Retrieval Augmented Generation (RAG) for Question Answering\n",
    "    - 3-3 RAG Limitations <br>\n",
    "\n",
    "\n",
    "- <b> Session 4. Efficient Text Splitting and Indexing with LangChain </b>:  Efficiently build a RAG system by loading external documents, splitting them into smaller chunks, using embedding APIs to store them in a vectorspace, and retrieving them.<br>\n",
    "\n",
    "- <b> Session 5. Gradio </b>: Use Gradio and RAG techniques to process PDF documents and generate real-time, interactive responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: typer 0.12.5 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mzsh:1: no matches found: arize-phoenix[evals]\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -qU guardrails-ai openai langchain_community langchain_experimental langchain-upstage sentence-transformers langchainhub langchain-chroma langchain matplotlib python-dotenv tavily-python ragas faiss-cpu tokenizers getpass4\n",
    "!pip3 install -q arize-phoenix[evals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 1] HELLO SOLAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "<b> Introduction to Solar Framework </b>: Learn the basics of setting up the Solar LLM framework and running a simple \"Hello, World!\" example to understand its core functionality.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPSTAGE_API_KEY\n",
    "To obtain your Upstage API key, follow these steps:\n",
    "\n",
    "1. Visit the Upstage AI console at <https://console.upstage.ai>.\n",
    "2. Sign up for an account if you don't already have one.\n",
    "3. Log in to your account.\n",
    "4. Navigate to the API key section.\n",
    "5. Generate your API key.\n",
    "6. Copy the key and save it securely.\n",
    "\n",
    "![Console](./figures/console.upstage.ai.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# UPSTAGE_API_KEY from https://console.upstage.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title set API key\n",
    "import os\n",
    "import getpass\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Running in Google Colab. Please set the UPSTAGE_API_KEY in the Colab Secrets\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
    "else:\n",
    "    # Running locally. Please set the UPSTAGE_API_KEY in the .env file\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "if \"UPSTAGE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = getpass.getpass(\"Enter your Upstage API key: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1-1 Interacting with the Solar-1-mini-chat Model\n",
    "\n",
    "This Python code demonstrates how to use the OpenAI API to interact with the Solar-1-mini-chat model provided by Upstage AI.\n",
    "\n",
    "##### Steps\n",
    "\n",
    "1. Import necessary libraries: `os`, `openai`, and `pprint`.\n",
    "2. Set up the OpenAI client with the API key and base URL.\n",
    "3. Create a chat completion request using `client.chat.completions.create()`.\n",
    "   - Specify the model: \"solar-1-mini-chat\".\n",
    "   - Provide a list of messages, including the system message and user message.\n",
    "4. Handle the model's response:\n",
    "   - Print the entire response using `pprint()`.\n",
    "   - Print the content of the assistant's message using `response.choices[0].message.content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='6e6780a3-7314-400a-a982-df24b4ad5eb4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Korea, also known as the Republic of Korea (ROK), is a country located on the Korean Peninsula in East Asia. It is bordered by China to the west and North Korea to the north. The capital and largest city is Seoul. Korea has a rich history, with a long-standing tradition of martial arts.\\n\\nThe traditional martial art of Korea is called Taekwondo, which is known for its high, fast, and spinning kicks. It is also characterized by fast kicking, jumping, and spinning techniques. Taekwondo is one of the most practiced martial arts in the world and is the national sport of Korea.\\n\\nAnother popular martial art from Korea is Hapkido, which emphasizes joint locks, throws, and grappling techniques, along with kicking and punching. It is known for its fluid movements and focus on circular striking techniques.\\n\\nKorea also has a long history of wrestling, called Ssireum, which is a traditional folk sport that has been practiced for over 2,000 years. It is a form of wrestling where the goal is to throw your opponent to the ground or make them touch the ground with any body part other than their feet.\\n\\nIn summary, Korea is known for its martial arts such as Taekwondo, Hapkido, and Ssireum, each with its unique characteristics and techniques.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727164281, model='solar-1-mini-chat-240612', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=302, prompt_tokens=26, total_tokens=328, completion_tokens_details=None))\n",
      "Message only:\n",
      "('Korea, also known as the Republic of Korea (ROK), is a country located on '\n",
      " 'the Korean Peninsula in East Asia. It is bordered by China to the west and '\n",
      " 'North Korea to the north. The capital and largest city is Seoul. Korea has a '\n",
      " 'rich history, with a long-standing tradition of martial arts.\\n'\n",
      " '\\n'\n",
      " 'The traditional martial art of Korea is called Taekwondo, which is known for '\n",
      " 'its high, fast, and spinning kicks. It is also characterized by fast '\n",
      " 'kicking, jumping, and spinning techniques. Taekwondo is one of the most '\n",
      " 'practiced martial arts in the world and is the national sport of Korea.\\n'\n",
      " '\\n'\n",
      " 'Another popular martial art from Korea is Hapkido, which emphasizes joint '\n",
      " 'locks, throws, and grappling techniques, along with kicking and punching. It '\n",
      " 'is known for its fluid movements and focus on circular striking techniques.\\n'\n",
      " '\\n'\n",
      " 'Korea also has a long history of wrestling, called Ssireum, which is a '\n",
      " 'traditional folk sport that has been practiced for over 2,000 years. It is a '\n",
      " 'form of wrestling where the goal is to throw your opponent to the ground or '\n",
      " 'make them touch the ground with any body part other than their feet.\\n'\n",
      " '\\n'\n",
      " 'In summary, Korea is known for its martial arts such as Taekwondo, Hapkido, '\n",
      " 'and Ssireum, each with its unique characteristics and techniques.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"UPSTAGE_API_KEY\"], base_url=\"https://api.upstage.ai/v1/solar\"\n",
    ")\n",
    "chat_result = client.chat.completions.create(\n",
    "    model=\"solar-1-mini-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What about Korea?\"},\n",
    "    ],\n",
    ")\n",
    "pprint(chat_result)\n",
    "print(\"Message only:\")\n",
    "pprint(chat_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2 Using Few-Shot Examples in Chat Completions\n",
    "\n",
    "This Python code demonstrates how to use few-shot examples in the OpenAI Chat Completions API to provide context and guide the model's responses.\n",
    "\n",
    "##### Steps\n",
    "\n",
    "1. Set up the OpenAI client with the API key and base URL.\n",
    "2. Create a chat completion request using `client.chat.completions.create()`.\n",
    "   - Specify the model: \"solar-1-mini-chat\".\n",
    "   - Provide a list of messages, including:\n",
    "     - System message: Defines the assistant's role.\n",
    "     - Few-shot examples: Provide context and desired behavior.\n",
    "     - User input: The actual user query.\n",
    "3. Handle the model's response:\n",
    "   - Print the entire response using `pprint()`.\n",
    "   - Print the content of the assistant's message using `response.choices[0].message.content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='6ede28d1-441a-4de1-bd21-1d4d84e52c32', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of South Korea is Seoul, while the capital of North Korea is Pyongyang.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727164284, model='solar-1-mini-chat-240612', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=21, prompt_tokens=55, total_tokens=76, completion_tokens_details=None))\n",
      "Message only:\n",
      "('The capital of South Korea is Seoul, while the capital of North Korea is '\n",
      " 'Pyongyang.')\n"
     ]
    }
   ],
   "source": [
    "# few shots: examples or history\n",
    "chat_result = client.chat.completions.create(\n",
    "    model=\"solar-1-mini-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        # examples\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"I know of it. It's Paris!!\",\n",
    "        },\n",
    "        # user input\n",
    "        {\"role\": \"user\", \"content\": \"What about Korea?\"},\n",
    "    ],\n",
    ")\n",
    "pprint(chat_result)\n",
    "print(\"Message only:\")\n",
    "pprint(chat_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 2] Building LLM Applications with LangChain\n",
    "\n",
    "This Python code demonstrates how to use the LangChain library to build applications with Large Language Models (LLMs). It covers the basic steps of defining an LLM, creating a chat prompt, defining a chain, and invoking the chain.\n",
    "\n",
    "#### Steps\n",
    "\n",
    "1. Define your favorite LLM:\n",
    "   - Import the `ChatUpstage` class from `langchain_upstage`.\n",
    "   - Create an instance of `ChatUpstage` and assign it to the variable `llm`.\n",
    "\n",
    "2. Define a chat prompt:\n",
    "   - Import the `ChatPromptTemplate` class from `langchain_core.prompts`.\n",
    "   - Create a `ChatPromptTemplate` instance using the `from_messages()` method.\n",
    "   - Provide a list of messages, including system messages, example conversations, and user input.\n",
    "\n",
    "3. Define a chain:\n",
    "   - Import the `StrOutputParser` class from `langchain_core.output_parsers`.\n",
    "   - Create a chain by combining the `rag_with_history_prompt`, `llm`, and `StrOutputParser()` using the pipe (`|`) operator.\n",
    "\n",
    "4. Invoke the chain:\n",
    "   - Call the `invoke()` method on the `chain` object, passing an empty dictionary (`{}`) as the input.\n",
    "   - Print the response obtained from the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm an AI and don't have feelings, so I'm always doing great. How about you?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 16, 'total_tokens': 42, 'completion_tokens_details': None}, 'model_name': 'solar-1-mini-chat-240612', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7597cce2-acd6-4a8e-8525-e003a51541bb-0', usage_metadata={'input_tokens': 16, 'output_tokens': 26, 'total_tokens': 42})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick hello world\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "llm = ChatUpstage()\n",
    "llm.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Korea, it depends on which part of Korea you're referring to. If it's North Korea, the capital is Pyongyang. For South Korea, the capital is Seoul.\n"
     ]
    }
   ],
   "source": [
    "# langchain, 1. llm define, 2. prompt define, 3. chain, 4. chain.invoke\n",
    "\n",
    "# 1. define your favorate llm, solar\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "# 2. define chat prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"What is the capital of France?\"),\n",
    "        (\"ai\", \"I know of it. It's Paris!!\"),\n",
    "        (\"human\", \"What about Korea?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 3. define chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. invoke the chain\n",
    "c_result = chain.invoke({})\n",
    "print(c_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameterized Prompt Templates in LangChain\n",
    "\n",
    "##### Overview\n",
    "\n",
    "- Prompt templates allow for reusable and modular prompts\n",
    "- They improve maintainability compared to using raw prompt strings\n",
    "- {country} value can be set from outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of South Korea is Seoul, while the capital of North Korea is Pyongyang.\n",
      "---\n",
      "Tokyo, I believe!!\n"
     ]
    }
   ],
   "source": [
    "# parameterized prompt template\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"What is the capital of France?\"),\n",
    "        (\"ai\", \"I know of it. It's Paris!!\"),\n",
    "        (\"human\", \"What about {country}?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. invoke chain with param\n",
    "print(chain.invoke({\"country\": \"Korea\"}))\n",
    "print(\"---\")\n",
    "print(chain.invoke({\"country\": \"Japan\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leveraging Message History in LangChain Prompts\n",
    "\n",
    "- LangChain provides powerful tools for managing conversation history\n",
    "- `MessagesPlaceholder` allows for dynamic inclusion of message history\n",
    "- `HumanMessage` and `AIMessage` classes represent individual messages\n",
    "- Combining message history with user input enables context-aware responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of South Korea is Seoul, and the capital of North Korea is Pyongyang.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# More general chat\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "history = [\n",
    "    HumanMessage(\"What is the capital of France?\"),\n",
    "    AIMessage(\"It's Paris!!\"),\n",
    "]\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "chain_result = chain.invoke({\"history\": history, \"input\": \"What about Korea?\"})\n",
    "print(chain_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain of Thought Prompting\n",
    "\n",
    "![CoT](figures/cot.webp)\n",
    "\n",
    "from https://arxiv.org/abs/2201.11903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cafeteria started with 23 apples. After using 20 of them, they would have:\\n\\n23 - 20 = 3 apples left.\\n\\nThen they bought 6 more apples, so they added those to the remaining apples:\\n\\n3 + 6 = 9 apples.\\n\\nTherefore, the cafeteria has 9 apples left.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Q: The cafeteria had 23 apples. \n",
    "If they used 20 to make lunch and bought 6 more, \n",
    "how many apples do they have?\n",
    "\n",
    "A: the answer is\n",
    "\"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cafeteria started with 23 apples. They used 20, so they had 3 apples left. They bought 6 more apples, so they now have 3 + 6 = 9 apples. The answer is 9.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls\n",
    "each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
    "\n",
    "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learn more advanced techniques by reading blog posts on Prompt Engineering!\n",
    "\n",
    "\n",
    "1. [[Prompt Engineering - Part 1] Maximizing the Use of LLM with Prompt Design](https://www.upstage.ai/feed/insight/prompt-engineering-guide-maximizing-the-use-of-llm-with-prompt-design)\n",
    "2. [[Prompt Engineering - Part 2] The Essence of Prompt Engineering: A Comprehensive Guide to Maximizing LLM Usage](https://www.upstage.ai/feed/insight/prompt-engineering-guide-to-maximizing-llm-usage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Hallucinations\n",
    "\n",
    "<b> Understanding Model Hallucinations </b> : Discover how to identify, understand, and mitigate hallucinations to ensure accurate and reliable model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hallucination](./figures/hallucination.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Upstage DUS is a technique used in the field of computer vision and image processing to detect and track objects in video sequences. It stands for \"Dense Objects in Video Sequences.\"\\n\\nThe Upstage DUS technique is based on the assumption that objects in a video sequence can be represented as dense objects, which are objects with a high degree of spatial and temporal continuity. The method uses a combination of optical flow and appearance models to track objects in a video sequence.\\n\\nThe Upstage DUS technique has been shown to be effective in detecting and tracking objects in a variety of video sequences, including those with complex backgrounds and occlusions. It has been used in a number of applications, including surveillance, traffic monitoring, and human action recognition.\\n\\nOverall, the Upstage DUS technique is a powerful tool for object detection and tracking in video sequences, and it has the potential to be applied in a wide range of fields.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 196, 'prompt_tokens': 18, 'total_tokens': 214, 'completion_tokens_details': None}, 'model_name': 'solar-1-mini-chat-240612', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c0ed71eb-8850-4b72-9b1c-a49d1f7c091f-0', usage_metadata={'input_tokens': 18, 'output_tokens': 196, 'total_tokens': 214})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cannot say \"I don't know\" :-)\n",
    "# Because it is trained to complete the sentence and try to answer the question\n",
    "llm.invoke(\"What is Upstage DUS technique?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Token Prediction\n",
    "They are designed to generate the next words. It's also very difficult to know what we don't know.\n",
    "\n",
    "![image](https://jalammar.github.io/images/xlnet/gpt-2-autoregression-2.gif)\n",
    "\n",
    "Image from https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Can We Mitigate Hallucinations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 Groundedness Check with LangChain and Upstage\n",
    "![Groundedness](./figures/gc.png)\n",
    "\n",
    "[Groundedness Check](https://developers.upstage.ai/docs/apis/groundedness-check)\n",
    "\n",
    "#### High-Level Overview\n",
    "\n",
    "The provided code demonstrates how to perform a groundedness check using the LangChain library and the Upstage model. The groundedness check is a process of verifying whether the generated response is grounded in the given context. This is an important step in ensuring the quality and relevance of the generated output.\n",
    "\n",
    "The code uses the `UpstageGroundednessCheck` class from the `langchain_upstage` module to perform the groundedness check. It takes the context (a string of unique documents) and the generated response as input, and returns a verdict indicating whether the response is grounded or not.\n",
    "\n",
    "#### Detailed Explanation\n",
    "\n",
    "1. The code starts by importing the necessary module:\n",
    "   - `UpstageGroundednessCheck` from `langchain_upstage`: This class is used to perform the groundedness check.\n",
    "   \n",
    "\n",
    "2. An instance of the `UpstageGroundednessCheck` class is created and assigned to the variable `groundedness_check`.\n",
    "\n",
    "3. The input for the groundedness check is prepared by creating a dictionary called `request_input`:\n",
    "   - The `\"context\"` key is assigned the value of `str(unique_docs)`, which represents the unique documents as a string.\n",
    "   - The `\"answer\"` key is assigned the value of `response`, which represents the generated response.\n",
    "   \n",
    "\n",
    "4. The `invoke` method of the `groundedness_check` instance is called with the `request_input` as an argument. This method performs the groundedness check and returns the verdict.\n",
    "\n",
    "5. The verdict is stored in the `gc_result` variable and printed to the console using `print(gc_result)`.\n",
    "\n",
    "6. The code then checks if the `gc_result` starts with the word \"grounded\" (case-insensitive):\n",
    "   - If the response starts with \"grounded\", it means the groundedness check has passed, and the message \"✅ Groundedness check passed\" is printed.\n",
    "   - If the response does not start with \"grounded\", it means the groundedness check has failed, and the message \"❌ Groundedness check failed\" is printed.\n",
    "\n",
    "\n",
    "The provided code demonstrates a simple yet effective way to perform a groundedness check using LangChain and Upstage. By verifying whether the generated response is grounded in the given context, it helps ensure the quality and relevance of the output.\n",
    "\n",
    "Groundedness checks are an important step in building reliable and trustworthy language models and conversational agents. They help prevent the generation of irrelevant, inconsistent, or factually incorrect responses.\n",
    "\n",
    "By using the `UpstageGroundednessCheck` class from LangChain, developers can easily integrate groundedness checks into their language model pipelines and improve the overall performance of their systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grounded\n",
      "✅ Groundedness check passed\n"
     ]
    }
   ],
   "source": [
    "# GC\n",
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "groundedness_check = UpstageGroundednessCheck()\n",
    "\n",
    "context = \"DUS is a new approach developed by Upstage to improve the search quality.\"\n",
    "answer = \"DUS is developed by Upstage.\"\n",
    "\n",
    "request_input = {\n",
    "    \"context\": context,\n",
    "    \"answer\": answer,\n",
    "}\n",
    "gc_result = groundedness_check.invoke(request_input)\n",
    "\n",
    "print(gc_result)\n",
    "if gc_result.lower().startswith(\"grounded\"):\n",
    "    print(\"✅ Groundedness check passed\")\n",
    "else:\n",
    "    print(\"❌ Groundedness check failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Groundedness check failed\n"
     ]
    }
   ],
   "source": [
    "context = \"DUS is a new approach developed by Upstage to improve the search quality.\"\n",
    "answer = \"DUS is developed by Google.\"\n",
    "\n",
    "request_input = {\n",
    "    \"context\": context,\n",
    "    \"answer\": answer,\n",
    "}\n",
    "gc_result = groundedness_check.invoke(request_input)\n",
    "\n",
    "if gc_result.lower().startswith(\"grounded\"):\n",
    "    print(\"✅ Groundedness check passed\")\n",
    "else:\n",
    "    print(\"❌ Groundedness check failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 3] What is RAG?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide context and allow the language model to respond within that context only.\n",
    "\n",
    "![Overview](./figures/rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 Layout Analysis\n",
    "\n",
    "Leveraging Layout Analyzer and LangChain for Efficient Text Splitting and Vectorization\n",
    "\n",
    "- Upstage Layout Analyzer extracts layouts, tables, and figures from any document\n",
    "- LangChain provides powerful tools for text splitting and vectorization\n",
    "\n",
    "![Layout Analyzer](./figures/la.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import (\n",
    "    UpstageLayoutAnalysisLoader,\n",
    "    UpstageGroundednessCheck,\n",
    "    ChatUpstage,\n",
    "    UpstageEmbeddings,\n",
    ")\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "layzer = UpstageLayoutAnalysisLoader(\"pdfs/solar_paper.pdf\", output_type=\"html\")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "docs = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"<h1 id='0' style='font-size:20px'>SOLAR 10.7B: Scaling Large Language Models \"\n",
      " 'with Simple yet Effecti')\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    pprint(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 id='0' style='font-size:20px'>SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective<br>Depth Up-Scaling</h1><br><p id='1' data-category='paragraph' style='font-size:18px'>Dahyun Kim∗, Chanjun Park∗†, Sanghoon Kim∗†, Wonsung Lee∗†, Wonho Song∗<br>Yunsu Kim∗, Hyeonwoo Kim∗, Yungi Kim, Hyeonju Lee, Jihoo Kim<br>Changbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim<br>Mikyoung Cha, Hwalsuk Lee†, Sunghun Kim†</p><p id='2' data-category='paragraph' style='font-size:18px'>Upstage AI, South Korea</p><br><p id='3' data-category='paragraph' style='font-size:14px'>{kdahyun, chanjun.park, limerobot, wonsung.lee, hwalsuk.lee, hunkim}@upstage.ai</p><br><p id='4' data-category='paragraph' style='font-size:18px'>Abstract</p><br><p id='5' data-category='paragraph' style='font-size:14px'>We introduce SOLAR 10.7B, a large language<br>model (LLM) with 10.7 billion parameters,<br>demonstrating superior performance in various<br>natural language processing (NLP) tasks. "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(docs[0].page_content[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 Retrieval Augmented Generation (RAG) for Question Answering\n",
    "\n",
    "- RAG combines retrieval and generation to enhance LLM performance on specific tasks\n",
    "- Relevant context is retrieved from external data sources and added to the prompt\n",
    "- The augmented prompt is then passed to the LLM for generating a response\n",
    "- RAG is particularly useful for question answering on custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE1\n",
      " Table 6 presents the performance comparison among the merge candidates. 'Cand. 1' and 'Cand. 2' are trained using the same setting as 'DPO v2' and 'DPO v3', respectively, but with slightly different hyper-parameters. The table shows that 'Cand. 1' has high GSM8K scores but relatively low scores for the other tasks, whereas 'Cand. 2' has low scores for GSM8K but high scores for the other tasks.\n"
     ]
    }
   ],
   "source": [
    "# More general chat\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question considering the history of the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "---\n",
    "CONTEXT:\n",
    "{context}\n",
    "         \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "history = []\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "query1 = \"Performance comparison amongst the merge candidate\"\n",
    "response1 = chain.invoke({\"history\": history, \"context\": docs, \"input\": query1})\n",
    "print(\"RESPONSE1\\n\", response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE2\n",
      " The document provides ablation studies on the different datasets used for instruction tuning and alignment tuning, as well as the different SFT base models used for alignment tuning and the model merging strategy to obtain the final alignment-tuned model.\n",
      "\n",
      "For instruction tuning, the ablation studies show the impact of using different datasets, such as Alpaca-GPT4, OpenOrca, and Synth. Math-Instruct. The study found that adding the Synth. Math-Instruct dataset is beneficial for improving the GSM8K score. The study also found that merging models trained with and without OpenOrca can boost performance.\n",
      "\n",
      "For alignment tuning, the ablation studies show the impact of using different datasets, such as Ultrafeedback Clean and Synth. Math-Alignment, and the impact of using different SFT base models. The study found that adding Synth. Math-Alignment to the training dataset improves the GSM8K score, but merging models trained with and without Synth. Math-Alignment does not always improve performance. The study also found that using a merged SFT base model for alignment tuning can improve performance.\n"
     ]
    }
   ],
   "source": [
    "history = [HumanMessage(query1), AIMessage(response1)]\n",
    "query2 = \"How about Ablation studies?\"\n",
    "response2 = chain.invoke({\"history\": history, \"context\": docs, \"input\": query2})\n",
    "print(\"RESPONSE2\\n\", response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3  RAG Limitations\n",
    "- LLM does not have long enough context length\n",
    "- Sending long, irrelevant info is inefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load something big\n",
    "layzer = UpstageLayoutAnalysisLoader(\n",
    "    \"pdfs/kim-tse-2008.pdf\", output_type=\"html\", use_ocr=True\n",
    ")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "docs = layzer.load()  # or layzer.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"This model's maximum context length is 32768 tokens. However, your messages resulted in 36080 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "# More general chat\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question considering the history of the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "---\n",
    "CONTEXT:\n",
    "{context}\n",
    "         \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "query1 = \"What is bug classification?\"\n",
    "\n",
    "try:\n",
    "    response1 = chain.invoke({\"history\": history, \"context\": docs, \"input\": query1})\n",
    "    print(response1)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107118\n"
     ]
    }
   ],
   "source": [
    "print(len(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_pretrained(\"upstage/solar-1-mini-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded input: ['<|startoftext|>', '▁Nice', '▁to', '▁meet', '▁you', '.', '▁I', '▁am', '▁Solar', '▁LL', 'M', ',', '▁a', '▁large', '▁language', '▁model', '▁developed', '▁by', '▁Up', 'stage', '.', '▁If', '▁you', '▁have', '▁any', '▁questions', ',', '▁please', '▁feel', '▁free', '▁to', '▁ask', '.']\n",
      "Number of tokens: 33\n"
     ]
    }
   ],
   "source": [
    "text = \"Nice to meet you. I am Solar LLM, a large language model developed by Upstage. If you have any questions, please feel free to ask.\"\n",
    "\n",
    "enc = tokenizer.encode(text)\n",
    "print(\"Encoded input:\", enc.tokens)\n",
    "\n",
    "number_of_tokens = len(enc.tokens)\n",
    "print(\"Number of tokens:\", number_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded input: ['<|startoftext|>', '▁만나', '서', '▁반가', '워', '요', '.', '▁저는', '▁Up', 'stage', '에서', '▁개발한', '▁대규모', '▁언어', '▁모델', '인', '▁Solar', '▁LL', 'M', '▁입니다', '.', '▁궁금한', '▁것이', '▁있으', '시면', '▁무엇이', '든', '▁물어', '보세요', '.']\n",
      "Number of tokens: 30\n"
     ]
    }
   ],
   "source": [
    "text = \"만나서 반가워요. 저는 Upstage에서 개발한 대규모 언어 모델인 Solar LLM 입니다. 궁금한 것이 있으시면 무엇이든 물어보세요.\"\n",
    "enc = tokenizer.encode(text)\n",
    "print(\"Encoded input:\", enc.tokens)\n",
    "\n",
    "number_of_tokens = len(enc.tokens)\n",
    "print(\"Number of tokens:\", number_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_tokens(text):\n",
    "    return len(tokenizer.encode(text).tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG 33\n",
      "KOR 30\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"ENG\",\n",
    "    num_of_tokens(\n",
    "        \"Nice to meet you. I am Solar LLM, a large language model developed by Upstage. If you have any questions, please feel free to ask.\"\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"KOR\",\n",
    "    num_of_tokens(\n",
    "        \"만나서 반가워요. 저는 Upstage에서 개발한 대규모 언어 모델인 Solar LLM 입니다. 궁금한 것이 있으시면 무엇이든 물어보세요.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String length 107118\n",
      "Number of tokens 34907\n"
     ]
    }
   ],
   "source": [
    "# Recall\n",
    "# Let's load something big\n",
    "# layzer = UpstageLayoutAnalysisLoader(\"pdfs/kim-tse-2008.pdf\", output_type=\"html\")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "# docs = layzer.load()  # or layzer.lazy_load()\n",
    "print(\"String length\", len(docs[0].page_content))\n",
    "print(\"Number of tokens\", num_of_tokens(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 4] Efficient Text Splitting and Indexing with LangChain\n",
    "\n",
    "\n",
    "### Steps\n",
    "<b> 1. Load Documents </b>\n",
    "\n",
    "The first step is to load the source documents that will be used to augment the language model's knowledge\n",
    "This could be done by reading files from disk, pulling from a database, scraping web pages, etc.\n",
    "The goal is to get the raw text content into a format that can be further processed\n",
    "\n",
    "<b>2. Chunking/Splitting</b>\n",
    "\n",
    "* Long documents need to be broken down into smaller chunks that are a manageable size for embedding and retrieval\n",
    "Common approaches include:\n",
    "  * Fixed-size chunking - split text into equal sized chunks based on character or token count \n",
    "  * Semantic chunking - split based on semantic boundaries like sentences, paragraphs, or sections\n",
    "  * Hierarchical chunking - create chunks at multiple levels of granularity\n",
    "The ideal chunk size depends on the embedding model, retrieval use case, and downstream task\n",
    "\n",
    "<b>3. Embedding & Indexing</b>\n",
    "\n",
    "* The text chunks are converted to vector embeddings using a model like Upstage embeddings\n",
    "* The embeddings are indexed and stored in a vector database to enable efficient similarity search \n",
    "* Metadata about the source chunks can also be stored alongside the embeddings\n",
    "\n",
    "<b>4. Retrieval</b>\n",
    "\n",
    "* At query time, the user's question is itself embedded as a query vector\n",
    "* The query embedding is used to find the most similar document chunks in the vector index \n",
    "* Top-k most relevant chunks are retrieved and can be used to augment the prompt sent to the language model to generate an answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RecursiveCharacterTextSplitter\n",
    "\n",
    " `RecursiveCharacterTextSplitter` class is designed to be recursively split so that semantically related pieces remain together. <br>\n",
    " During this process, a list of delimiter characters `(['\\n\\n', '\\n', ' ', ''])` is used sequentially to partition the text. \n",
    "- This splitting continues until the resulting chunks are smaller than the specified `chunk_size`. \n",
    "- The `chunk_overlap` parameter defines the number of characters that should overlap between the divided text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 1. load doc (done), 2. chunking, splits, 3. embeding - indexing, 4. retrieve\n",
    "\n",
    "# layzer = UpstageLayoutAnalysisLoader(\"pdfs/kim-tse-2008.pdf\", output_type=\"html\")\n",
    "# # For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "# docs = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 129\n"
     ]
    }
   ],
   "source": [
    "# 2. Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(\"Splits:\", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "split_lengths = [len(split.page_content) for split in splits]\n",
    "\n",
    "# Create a bar graph\n",
    "plt.bar(range(len(split_lengths)), split_lengths)\n",
    "plt.title(\"RecursiveCharacterTextSplitter\")\n",
    "plt.xlabel(\"Split Index\")\n",
    "plt.ylabel(\"Split Content Length\")\n",
    "plt.xticks(range(len(split_lengths)), [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.73 s, sys: 253 ms, total: 2.98 s\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3. Embed & indexing\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, embedding=UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Bugs Are,\"<br>Proc. ACM Int'l Symp. Software Testing and Analysis, pp· 86-96,<br>2004.<br>[41] K. Pa\n"
     ]
    }
   ],
   "source": [
    "# 4. retrive\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "result_docs = retriever.invoke(\"What is Bug Classification?\")\n",
    "print(len(result_docs))\n",
    "print(result_docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SemanticChunker\n",
    "\n",
    "SemanticChunker is an experimental feature in LangChain that serves to split text into semantically similar chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overview](./figures/semantic_chunker.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2. SemanticChunker Split\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "def semantic_chunker(\n",
    "    docs,\n",
    "    min_chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    max_chunk_size=1000,\n",
    "    merge_threshold=0.7,\n",
    "    embeddings=UpstageEmbeddings(model=\"solar-embedding-1-large\"),\n",
    "):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=min_chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    init_splits = text_splitter.split_documents(docs)\n",
    "    splits = []\n",
    "\n",
    "    base_split_text = None\n",
    "    base_split_emb = None\n",
    "    for split in init_splits:\n",
    "        if base_split_text is None:\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = embeddings.embed_documents([base_split_text])[0]\n",
    "            continue\n",
    "\n",
    "        split_emb = embeddings.embed_documents([split.page_content])[0]\n",
    "        distance = cosine_similarity(X=[base_split_emb], Y=[split_emb])\n",
    "        if (\n",
    "            distance[0][0] < merge_threshold\n",
    "            or len(base_split_text) + len(split.page_content) > max_chunk_size\n",
    "        ):\n",
    "            splits.append(Document(page_content=base_split_text))\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = split_emb\n",
    "        else:\n",
    "            base_split_text += split.page_content\n",
    "\n",
    "    if base_split_text:\n",
    "        splits.append(Document(page_content=base_split_text))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFaceEmbeddings\n",
    "Since it's just an approximation, it's acceptable to use very light embedding models like KLUE, https://huggingface.co/klue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "No sentence-transformers model found with name klue/roberta-small. Creating a new one with mean pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.48 s, sys: 933 ms, total: 3.42 s\n",
      "Wall time: 6.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "hfembeddings = HuggingFaceEmbeddings(model_name=\"klue/roberta-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemanticChunker Splits: 242\n",
      "CPU times: user 1min 10s, sys: 17.9 s, total: 1min 28s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "semantic_splits = semantic_chunker(docs, merge_threshold=0.8, embeddings=hfembeddings)\n",
    "print(\"SemanticChunker Splits:\", len(semantic_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "split_lengths = [num_of_tokens(split.page_content) for split in semantic_splits]\n",
    "\n",
    "# Create a bar graph\n",
    "plt.bar(range(len(split_lengths)), split_lengths)\n",
    "plt.xlabel(\"Split Index\")\n",
    "plt.ylabel(\"Split Content Length\")\n",
    "plt.title(\"Semantic Chunker Split Page Content Lengths\")\n",
    "plt.xticks(range(len(split_lengths)), [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChromaParallel Class: Parallel Document Embedding\n",
    "The ChromaParallel class is an extension of the Chroma class to enable parallel processing of document embedding and storage using multiple worker processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chroma is an AI-native open source vector database designed to enhance developer productivity and satisfaction. It is licensed under the Apache 2.0 license. \n",
    "\n",
    "- <b> Generate Vectorspace </b> : The `from_documents` class method creates a vector store from a list of documents.\n",
    "\n",
    "##### Reference\n",
    "\n",
    "* [Chroma LangChain Documentation](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/)\n",
    "* [Chroma Official Documentation](https://docs.trychroma.com/getting-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "class ChromaParallel(Chroma):\n",
    "\n",
    "    async def afrom_documents(documents, embedding, num_workers=2):\n",
    "        db = Chroma(embedding_function=embedding)\n",
    "        # create list of num_workers empty lists\n",
    "        doc_groups = [[] for _ in range(num_workers)]\n",
    "\n",
    "        for i in range(len(documents)):\n",
    "            doc_groups[i % num_workers].append(documents[i])\n",
    "\n",
    "        tasks = [db.aadd_documents(group) for group in doc_groups]\n",
    "        await asyncio.gather(*tasks)\n",
    "        return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='<h1 id='2' style='font-size:22px'>Classifying Software Changes:<br>Clean or Buggy?</h1><br><p id='3' data-category='paragraph' style='font-size:22px'>Sunghun Kim, E. James Whitehead Jr., Member, IEEE, and Yi Zhang, Member, IEEE</p><p id='4' data-category='paragraph' style='font-size:16px'>Abstract-This paper introduces a new technique for predicting latent software bugs, called change classification. Change<br>classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or<br>clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using<br>features (in the machine learning sense) extracted from the revision history of a software project stored in its software configuration<br>management repository. The trained classifier can classify changes as buggy or clean, with a 78 percent accuracy and a 60 percent<br>buggy change recall on average.' metadata={'total_pages': 16}\n",
      "Wall time: 23.29 sec\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "now = time.time()\n",
    "\n",
    "# 3. Embed & indexing\n",
    "loop = asyncio.get_event_loop()\n",
    "semantic_vectorstore = await ChromaParallel.afrom_documents(\n",
    "    documents=semantic_splits,\n",
    "    embedding=UpstageEmbeddings(model=\"solar-embedding-1-large\"),\n",
    "    num_workers=3,\n",
    ")\n",
    "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 4. retrive\n",
    "result_docs = semantic_retriever.invoke(\"What is Bug Classification?\")\n",
    "print(result_docs[1])\n",
    "print(f\"Wall time: {time.time() - now:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug classification is a process in software engineering where bugs or defects in a software system are categorized or grouped based on certain criteria. The purpose of bug classification is to help developers and quality assurance teams better understand the nature and impact of the bugs, prioritize them for fixing, and track their progress.\n",
      "\n",
      "Bug classification typically involves assigning labels or tags to each bug, such as severity level, priority, component affected, type of issue, and reproducibility. These labels help in organizing and filtering bugs for easier management.\n",
      "\n",
      "The process of bug classification usually works as follows:\n",
      "\n",
      "1. Identification: A bug is identified by a developer, tester, or user.\n",
      "2. Reporting: The bug is reported to the development team, often through a bug tracking system.\n",
      "3. Triage: The development team triages the bug report to verify its validity and understand the issue.\n",
      "4. Classification: Based on the information gathered, the bug is assigned appropriate labels or tags.\n",
      "5. Prioritization: The bugs are prioritized based on factors like severity, impact, and dependencies.\n",
      "6. Fixing: Developers work on fixing the highest priority bugs.\n",
      "7. Verification: Once a bug is fixed, it is verified to ensure that the issue has been resolved.\n",
      "8. Closure: The bug is marked as closed after verification.\n",
      "\n",
      "By classifying bugs, development teams can better allocate resources, manage workloads, and ensure that critical issues are addressed first. This helps in improving the overall quality and stability of the software system.\n"
     ]
    }
   ],
   "source": [
    "# Finally query using RAG\n",
    "query = \"What is bug classification? How it works?\"\n",
    "result_docs = semantic_retriever.invoke(query)\n",
    "\n",
    "gc_result = chain.invoke({\"history\": history, \"context\": result_docs, \"input\": query})\n",
    "print(gc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug classification is beneficial for several reasons:\n",
      "\n",
      "1. Improved Efficiency: By categorizing bugs, development teams can quickly identify and prioritize the most critical issues, allowing them to focus their efforts on fixing the most impactful bugs first.\n",
      "\n",
      "2. Better Resource Allocation: With a clear understanding of the nature and impact of each bug, teams can allocate resources more effectively, ensuring that the right people are working on the right issues.\n",
      "\n",
      "3. Enhanced Collaboration: Bug classification provides a common language and framework for developers, testers, and other stakeholders to discuss and manage bugs. This helps in better communication and collaboration within the team.\n",
      "\n",
      "4. Increased Transparency: By classifying bugs and making this information available to all team members, everyone can have a clear understanding of the current state of the software and the progress being made in resolving issues.\n",
      "\n",
      "5. Improved Quality: By addressing bugs systematically and prioritizing their fixes, teams can ensure that the software is continuously improved and that the overall quality is maintained or enhanced over time.\n",
      "\n",
      "6. Better Traceability: Classifying bugs can help in tracking the history and progress of each issue, making it easier to identify patterns, recurring problems, and the effectiveness of the fixes applied.\n",
      "\n",
      "7. Customer Satisfaction: By effectively managing and resolving bugs, teams can ensure that the software meets customer expectations and provides a better user experience, leading to increased customer satisfaction and loyalty.\n",
      "\n",
      "In summary, bug classification is a crucial process that helps development teams manage and resolve bugs more efficiently, leading to improved software quality, increased customer satisfaction, and better overall project outcomes.\n"
     ]
    }
   ],
   "source": [
    "history = [HumanMessage(query), AIMessage(gc_result)]\n",
    "\n",
    "query = \"Why it is good?\"\n",
    "result_docs = semantic_retriever.invoke(query)\n",
    "\n",
    "gc_result = chain.invoke({\"history\": history, \"context\": result_docs, \"input\": query})\n",
    "print(gc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For an in-depth look at the different types of RAG, please refer to the files '09. Smart RAG' and '10. Tool_RAG'.\n",
    "\n",
    "- [09. Smart RAG.ipynb](https://github.com/UpstageAI/cookbook/blob/main/cookbooks/upstage/Solar-Full-Stack-LLM-101/09_Smart_RAG.ipynb)\n",
    "- [10. Tool_RAG.ipynb](https://github.com/UpstageAI/cookbook/blob/main/cookbooks/upstage/Solar-Full-Stack-LLM-101/10_tool_RAG.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 5] Gradio\n",
    "\n",
    "<b> Comprehensive RAG System for PDFs </b> : Use Gradio and RAG techniques to process PDF documents and generate real-time, interactive responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU gradio python-dotenv langchain-upstage python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "from langchain_upstage import (\n",
    "    ChatUpstage,\n",
    "    UpstageEmbeddings,\n",
    "    UpstageLayoutAnalysisLoader,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "llm = ChatUpstage(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More general chat\n",
    "chat_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{message}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_with_history_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history_langchain_format = []\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "\n",
    "    return chain.invoke({\"message\": message, \"history\": history_langchain_format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.ChatInterface(\n",
    "        chat,\n",
    "        examples=[\n",
    "            \"How to eat healthy?\",\n",
    "            \"Best Places in Korea\",\n",
    "            \"How to make a chatbot?\",\n",
    "        ],\n",
    "        title=\"Solar Chatbot\",\n",
    "        description=\"Upstage Solar Chatbot\",\n",
    "    )\n",
    "    chatbot.chatbot.height = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Building Your Own AI-Powered Chatbot! 🤖\n",
    "\n",
    "\n",
    "Congratulations on completing the course on building chatbots using Language Models (LLMs), Layout Analysis (LA), custom tools, and Groundedness Checks (GC)! Now, showcase your brilliant ideas by participating in a hackathon and leveraging the Solar API! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
